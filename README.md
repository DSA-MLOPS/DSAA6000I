# DSA 6000E: Model to Production: ML Ops for Real Industry
### Spring 2024: Friday 9:00AM-11:50PM HKT @Rm202, W4 or Zoom

## Co-instructors
* Sung Kim
* Jungwoo Ha (Adjunct Prof)

## Course Overview:
This course will provide students with a comprehensive understanding of Large Language Models (LLMs) and their practical applications in a production environment, using LLM Ops methodology. We will explore the latest developments in LLMs and LLM Ops, as well as hands-on training in developing, deploying, and evaluating LLMs.

## Potential Project Topics:
TBA

## Grading breakdown:

* Participations: 10%
* Inclass test: 10%
* Homework: 30%
* Mid-project proposal: 20%
* Final project: 30%

## Course Outline:

### Week 1 Jan 26 (No class)
- HW1 (read and one-page report) and submit one page summary for each paper
  *  Transformer: https://arxiv.org/abs/1706.03762
  *  GPT3.5: https://arxiv.org/abs/2203.02155

### Week 2 Feb 2: In-class finetuning and test - GZ
- TA will explain basic code of finetuning 1 hour
- Online test after that. Students must have more than 70 to enroll this class
- Simple example: https://github.com/facebookresearch/llama-recipes/blob/main/examples/quickstart.ipynb
- https://artificialcorner.com/mastering-llama-2-a-comprehensive-guide-to-fine-tuning-in-google-colab-bedfcc692b7f
- https://huggingface.co/docs/trl/index
- https://aws.amazon.com/blogs/machine-learning/fine-tune-llama-2-for-text-generation-on-amazon-sagemaker-jumpstart/
- https://github.com/facebookresearch/llama-recipes

### Spring Festival Break Feb 9

### Spring Festival Break Feb 16

### Feb 19: (Optional) Dinner  GZ 

### Week 4 Feb 23: Introduction to Large Language Models (LLMs) and LLM Ops (Sung Kim) @GZ + Zoom

### Week 5 Mar 1: A Survey of Large Language Models (John) @GZ
 - Reader paper in advance: https://arxiv.org/abs/2303.18223 

### Week 6 Mar 8: Matthias Gall√© from Cohere (7AM HKT) @GZ

### Week 7 Mar 15: LLM project proposal. 

### Week 8 Mar 22: QWen 2.0 @Zoom

### Week 9 Mar 29: LLM pre-training, ecosystem, and Sovereign LLM (Jung-Woo Ha, Head of Naver AI, Adjunct Prof at HKUST) @Zoom

### Qingming Festival Break Apr 5

### Week 10 Apr 12: LLM Applications and Evaluations 
- Read: LLM Evaluations, https://arxiv.org/abs/2307.03109

  
### Week 11 Apr 19 AI Regulations (Hwaran Lee from Naver) Zoom
* Talk1: Hwran Lee from Naver

### Week 12 Apr 26: Project Presentations Poster session GZ
- Students will learn about monitoring and maintenance techniques for LLM models in a production environment, and will set up monitoring and alerting mechanisms for their deployed models.
- Final project presentations to the class, and feedback from instructors and peers.
- Course review and wrap-up.

Overall, the course will provide students with a solid understanding of LLM Ops methodology, as well as hands-on experience in developing, deploying, and evaluating LLMs in a production environment. This skill set is essential for any career in the field of natural language processing. The course will be co-taught by Sung Kim and Jungwoo Ha, who have extensive experience in the field and have worked on a variety of LLM-based projects.

We encourage students with a background in natural language processing, machine learning, or data science to enroll in this course. Students should have experience with programming languages such as Python, and familiarity with deep learning frameworks such as TensorFlow or PyTorch.



## References
* https://github.com/microsoft/LMOps
* https://scale.com/spellbook
* https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/
* https://huggingface.co/docs/transformers/training
* https://arxiv.org/abs/2303.12712

